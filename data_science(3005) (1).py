# -*- coding: utf-8 -*-
"""Data science(3005).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aQ2gfdDZ9em2Glbf--Vz18MsCCIlQa3a
"""







import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math

df=pd.read_csv("/content/dataset.csv")

df.head()

A= df['Rating'].mean()
print(A)

B=df['Salary'].mean()
print (B)

df['Rating'].median()

df['Salary'].median()

#mode
df['Rating'].mode()

df['Salary'].mode()

C=df['Salary'].std()
print (C)

D=df['Rating'].std()
print(D)

h=df['Salary'].var()
print(h)

#VARIANCE
df['Salary'].value_counts().to_frame().T

L1=list(df['Salary'])
L2=list(df['Rating'])

plt.title("bar plot")
plt.plot(df['Salary'])
plt.show()

df = pd.read_csv("/content/dataset.csv")
# creating a histogram
plt.title("histogram")
plt.hist(df['Salary'])
plt.show()

# Pearson Correlation Coefficient
def mean(data):
    return sum(data) / len(data)

def pearson_correlation(L1,L2):
    if len(L1) != len(L2):
        raise ValueError("Input lists must have the same length.")

    n = len(L1)


    numerator = sum (int(int(L1[i]- A)*(int(L2[i]-B)))for i in range(n))
    denominator = (n-1)*C*D

    correlation_coefficient = numerator / denominator

    return correlation_coefficient

# Input data as lists
x = L1
y = L2

correlation = pearson_correlation(L1, L2)
print("Pearson Correlation Coefficient:", C)

# normal distribution
def normal_distribution (L):
  X=1/(C*(2*math.pi)**1/2)*(math.e)**-1/2*((L-B)/C)**2
  print(X)
normal_distribution(100000)

import pandas as pd
data={'Salary':L1,
      "Ratings": L2}

df=pd.DataFrame(data)
display(df)

# min max
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler ()
normalized_data=scaler.fit_transform(df)
print(normalized_data)

#beyes thm
c1=0
for i in L1 :
  if i > 500000 :
    c1+=1
ph=c1/len(L1)
print ("probablity of number of employ having salary greater than 500000",ph)

c2=0
for i in L2:
  if i>3.9 :
   c2+=1

PD=c2/len(L2)
print("probability of rating greater than 3.9 ",PD)

c3=0
for i in L1:
  if i >200000:
   for j in L2:
    if j > 3.9:
      c3+=1
      break

PDh=c3/len(L1)
print("probability of salary grater then 200000 when probability of rating greater then 3.9 ",PDh)

def con_prob(a,b,c):
  P=(a*b)/c
  return P

X=con_prob(PDh,ph,PD)
print ("the probability ofn rating be greater than 3.9 when the salary is grater than 200000 ",X)

def Bayes():
   PHD=(PDh*ph)/PD
   print("probability of hypothesis given  data :",PHD )

Bayes()

# scatter plot
import matplotlib.pyplot as plt
import random

x=L1
y=L2
plt.scatter(x,y,)
plt.title("scatter plot")
plt.xlabel("salary")
plt.ylabel("rating")
plt.show()

import matplotlib.pyplot as plt
import random
x=L1
y=L2
plt.scatter(x,y,)
plt.title("scatter plot")
plt.xlabel("salary")
plt.ylabel("rating")
plt.show()

# student t-test independent
se1=C/len(L1)
print (se1)
se2=D/len(L2)
print (se2)
sed=math.sqrt(se1**2+se2**2)
print (sed)
t=(A-B)/sed
print(t)

#student t test dependent
n=len(L1)
print(n)


d1=sum(((L1[i]-L2[i])**2)for i in range(n))
d2=sum((L1[j]-L2[j])for j in range (n))
sd=math.sqrt((d1-(d2**2/n))/(n-1))
sed=sd/math.sqrt(n)
t=(A-B)/sed
print(t)
print(sd)
print(d1)
print(d2)

# linear regression
import matplotlib.pyplot as plt
from scipy import stats

x=L1
y=L2

slope ,intercept,r,p ,std_err=stats.linregress(x,y)

def myfunc(x):
  return slope*x+intercept
plt.title('linear regression ')

mymodel=list(map(myfunc,x))
plt.scatter(x,y)
plt.plot(x,mymodel)
plt.show()

# box plot
import matplotlib.pyplot as plt

# Sample data
data =L1# salary

# Create a box plot
plt.boxplot(data)

# Add labels and title
plt.xlabel('X-axis Label')
plt.ylabel('Y-axis Label')
plt.title('Box Plot Example')

# Show the plot
plt.show()

import scikitlearn as sl

import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Create a sample dataset (you should replace this with your actual data)
data = df(['rating']).value
data=df(['salary']).value
# Number of clusters you want to create
num_clusters = 2

# Create a K-Means model
kmeans = KMeans(n_clusters=num_clusters)

# Fit the model to your data
kmeans.fit(data)

# Get the cluster labels for each data point
labels = kmeans.labels_

# Get the cluster centers
cluster_centers = kmeans.cluster_centers_

# Visualize the data and clusters
plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis')
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1,], c='red', marker='x')
plt.title('K-Means Clustering')
plt.show()

